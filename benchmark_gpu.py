# -*- coding: utf-8 -*-
"""benchmark_gpu.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GSdr-6-jVzRhDcj1J_EFAWfsGoZNCJHR
"""

import torch
import time
import matplotlib.pyplot as plt
import numpy as np

# --- 1. SETTINGS ---
# Matrix size (Must be large to see the difference clearly)
SIZE = 10000
print(f"Benchmarking with Matrix Size: {SIZE}x{SIZE}")

# --- 2. CPU TEST ---
print("Running CPU Benchmark... (This might take a moment)")
start_time = time.time()
# Create random large matrices (on CPU)
cpu_matrix1 = torch.rand(SIZE, SIZE)
cpu_matrix2 = torch.rand(SIZE, SIZE)
# Matrix multiplication operation
result_cpu = torch.matmul(cpu_matrix1, cpu_matrix2)
end_time = time.time()
cpu_time = end_time - start_time
print(f"CPU Time: {cpu_time:.4f} seconds")

# --- 3. GPU TEST ---
if torch.cuda.is_available():
    print("Running GPU Benchmark...")
    # Set device to GPU (CUDA)
    device = torch.device("cuda")

    # Move data to GPU memory
    start_transfer = time.time()
    gpu_matrix1 = torch.rand(SIZE, SIZE, device=device)
    gpu_matrix2 = torch.rand(SIZE, SIZE, device=device)

    # Warm-up run (GPU initialization can be slow, so we exclude the first op)
    torch.matmul(gpu_matrix1, gpu_matrix2)
    torch.cuda.synchronize() # Wait for the warm-up to finish

    # Actual Benchmark
    start_event = torch.cuda.Event(enable_timing=True)
    end_event = torch.cuda.Event(enable_timing=True)

    start_event.record()
    result_gpu = torch.matmul(gpu_matrix1, gpu_matrix2)
    end_event.record()

    # Wait for operation to complete (Necessary because CUDA is asynchronous)
    torch.cuda.synchronize()

    # Calculate duration (elapsed_time returns milliseconds, converting to seconds)
    gpu_time = start_event.elapsed_time(end_event) / 1000
    print(f"GPU Time: {gpu_time:.4f} seconds")

    # Speedup Ratio
    speedup = cpu_time / gpu_time
    print(f"GPU Speedup: {speedup:.2f}x faster!")
else:
    gpu_time = 0
    print("GPU not detected. Please enable GPU in Colab Settings.")

# --- 4. PLOTTING GRAPH ---
labels = ['CPU', 'GPU']
times = [cpu_time, gpu_time]

plt.figure(figsize=(8, 6))
bars = plt.bar(labels, times, color=['blue', 'green'])
plt.ylabel('Time (Seconds) - Lower is Better')
plt.title(f'Matrix Multiplication Benchmark ({SIZE}x{SIZE})\nGPU Speedup: {speedup:.1f}x')

# Add time labels on top of bars
for bar in bars:
    yval = bar.get_height()
    plt.text(bar.get_x() + bar.get_width()/2, yval + 0.1, f'{yval:.4f}s', ha='center', va='bottom', fontweight='bold')

plt.show()